{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of core features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some imports and some plot settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio.v2 as iio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from collections import defaultdict\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from numpy.random import Generator\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generalizability import lower_bounds as gu\n",
    "from generalizability import kernels as ku\n",
    "from generalizability import probability_distributions as prob\n",
    "from generalizability import rankings_utils as ru\n",
    "from generalizability import mmd as mmd\n",
    "\n",
    "mpl.use(\"TkAgg\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"notebook\")\n",
    "palette = \"flare_r\"\n",
    "sns.set_palette(\"flare_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the hyperparameters from the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "DATA_DIR = Path(config['paths']['data_dir'])\n",
    "FIGURES_DIR = Path(config['paths']['figures_dir'])\n",
    "\n",
    "FORMAT = config['format']['output']\n",
    "\n",
    "SEED = config['parameters']['seed']\n",
    "RNG = np.random.default_rng(SEED)\n",
    "EPS = config['parameters']['epsilon']\n",
    "ALPHA = config['parameters']['alpha']\n",
    "LR_CONFIDENCE = config['parameters']['lr_confidence']\n",
    "CI_LOWER = (1 - LR_CONFIDENCE) / 2\n",
    "CI_UPPER = LR_CONFIDENCE + CI_LOWER\n",
    "\n",
    "DATA_SET = Path(config['data']['dataset_path'])\n",
    "EXPERIMENTAL_CONDITIONS = config['data']['experimental_conditions']\n",
    "TARGET = config['data']['target']\n",
    "ALTERNATIVES = config['data']['alternatives']\n",
    "\n",
    "DISJOINT = config['sampling']['disjoint']\n",
    "REPLACE = config['sampling']['replace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the data set into a pandas data frame and we check that only one value in the experimental conditions is set to `None`, indicating that it is variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SET.suffix == '.parquet':\n",
    "    df = pd.read_parquet(DATA_SET)\n",
    "elif DATA_SET.suffix == '.csv':\n",
    "    df = pd.read_csv(DATA_SET)\n",
    "else:\n",
    "    raise Exception(\"Please use a Parquet or CSV file as the format of your data\")\n",
    "\n",
    "assert sum(value is None for value in EXPERIMENTAL_CONDITIONS.values()) == 1, \"Exactly one element must be None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build a query from the experimental conditions dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \" and \".join(f\"{key} == '{value}'\" if isinstance(value, str) else f\"{key} == {value}\"\n",
    "                            for key, value in EXPERIMENTAL_CONDITIONS.items() if value is not None)\n",
    "\n",
    "# Check if query params exist in the df\n",
    "columns_to_check = set(EXPERIMENTAL_CONDITIONS.keys()).union({TARGET, ALTERNATIVES})\n",
    "missing_columns = columns_to_check - set(df.columns)\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"The following columns are missing from the dataframe: {missing_columns}\")\n",
    "\n",
    "# Build query\n",
    "df = df.query(query_string).reset_index(drop=True)\n",
    "rv = ru.get_rankings_from_df(df, factors=list(EXPERIMENTAL_CONDITIONS.keys()), alternatives=ALTERNATIVES,\n",
    "                             target=TARGET,\n",
    "                             lower_is_better=False, impute_missing=True)\n",
    "rv = rv.fillna(rv.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define some kernels that cana be used for MMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = {\n",
    "    \"mallows_auto\": (ku.mallows_kernel, {\"nu\": \"auto\"}),\n",
    "    \"jaccard_1\": (ku.jaccard_kernel, {\"k\": 1}),\n",
    "    #\"borda_OHE\": (ku.borda_kernel, {\"idx\": rv.index.get_loc(\"OHE\")}),\n",
    "    #\"borda_DE\": (ku.borda_kernel, {\"idx\": rv.index.get_loc(\"DE\")})\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will use the mallows kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNELNAME = \"mallows_auto\"\n",
    "KERNEL, KERNELARGS = kernels[KERNELNAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create some directories for the different experiments we run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create directories\n",
    "exp0_dir_name_parts = [f\"name={ALTERNATIVES}\"] + [f\"{key}={value}\" for key, value in EXPERIMENTAL_CONDITIONS.items() if value is not None]\n",
    "EXP0_DIR = FIGURES_DIR / \"_\".join(exp0_dir_name_parts)\n",
    "EXP1_DIR = EXP0_DIR / f\"{KERNELNAME}\"\n",
    "EXP2_DIR = EXP1_DIR / f\"nstar_N_ALPHA={ALPHA}_eps={EPS}_ci={LR_CONFIDENCE}_disjoint={DISJOINT}_replace={REPLACE}\"\n",
    "for ED in [EXP0_DIR, EXP1_DIR, EXP2_DIR]:\n",
    "    ED.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the experimental conditions pool to simulate running new experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7e43677c88c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_variable = next((key for key, value in EXPERIMENTAL_CONDITIONS.items() if value is None), None)\n",
    "ec_pool = df[ec_variable].unique()  # we remove experimental conditions from it to simulate running new experiments\n",
    "ecs = np.array([])  # ecs on which we have already run experiments\n",
    "out = []\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a few methods that will be run in a loop until our `ec_pool` is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by sampling from our `ec_pool` and converting our samples to the corresponding rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_compute_rankings(ecs, ec_pool, rv):\n",
    "    # Determine the number of samples to take\n",
    "    sample_size = min(10, len(ec_pool))\n",
    "    \n",
    "    # Sample experimental conditions\n",
    "    new_ecs = RNG.choice(ec_pool, sample_size, replace=False)\n",
    "    \n",
    "    # Update the list of sampled conditions\n",
    "    ecs = np.append(ecs, new_ecs)\n",
    "    \n",
    "    # Remove sampled conditions from the pool\n",
    "    ec_pool = np.setdiff1d(ec_pool, new_ecs)\n",
    "    \n",
    "    # Access and process the relevant data\n",
    "    rv_ = rv.loc[:, ecs]\n",
    "    \n",
    "    # Compute the shape of the dataframe\n",
    "    na, nv = rv_.shape\n",
    "    \n",
    "    # Generate rankings from the data\n",
    "    rankings = ru.SampleAM.from_rank_function_dataframe(rv_)\n",
    "    \n",
    "    return ecs, ec_pool, rankings, nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get compute the variance, variance lower bound and MMDs of these rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_variance_and_lower_bound(rankings):\n",
    "    \n",
    "    variance = ku.var(rankings, use_rv=True, kernel=KERNEL, **KERNELARGS)\n",
    "    \n",
    "    var_lower_bound = gu.sample_mean_embedding_lowerbound(EPS, len(ecs), kbar=1, v=variance)\n",
    "    \n",
    "    return variance, var_lower_bound\n",
    "\n",
    "def calculate_mmds(rankings, nv):\n",
    "    mmds = {\n",
    "        n: mmd.subsample_mmd_distribution(\n",
    "            rankings, subsample_size=n, rep=100, use_rv=True, use_key=False,\n",
    "            seed=SEED, disjoint=DISJOINT, replace=REPLACE, kernel=KERNEL, **KERNELARGS\n",
    "        )\n",
    "        for n in range(2, nv // 2 + 1)\n",
    "    }\n",
    "    return mmds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create dataframes consisting of Generalizability scores and Quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generalizability_dataframe(mmds, logepss):\n",
    "    ys = {n: [mmd.generalizability(mmde, np.exp(logeps)) for logeps in logepss] for n, mmde in mmds.items()}\n",
    "    dfy = pd.DataFrame(ys, index=logepss).reset_index().melt(id_vars='index', var_name='n', value_name='generalizability')\n",
    "    dfy.rename(columns={'index': 'log(eps)'}, inplace=True)\n",
    "    dfy['n'] = dfy['n'].astype(int)\n",
    "    return dfy\n",
    "\n",
    "def create_quantiles_dataframe(mmds):\n",
    "    qs = {n: np.log(np.quantile(mmde, ALPHA)) for n, mmde in mmds.items()}\n",
    "    dfq = pd.DataFrame(list(qs.items()), columns=['n', 'log(eps)'])\n",
    "    dfq['log(n)'] = np.log(dfq['n'])\n",
    "    return qs, dfq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the quantiles dataframe to calculate `nstar`. To this end, we fit linear regression models on subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_regression_with_cv(dfq):\n",
    "    # Extracting features and target from DataFrame\n",
    "    X = dfq[['log(eps)']].values\n",
    "    y = dfq[['log(n)']].values\n",
    "\n",
    "    cv = KFold(n_splits=len(y))\n",
    "\n",
    "    residuals, linear_predictors = [], []\n",
    "\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        lr = LinearRegression().fit(X[train_index], y[train_index])\n",
    "\n",
    "        predicted = lr.predict(X[test_index])\n",
    "        residuals.extend(y[test_index] - predicted)\n",
    "\n",
    "        linear_predictors.append(lr)\n",
    "\n",
    "    return linear_predictors, residuals\n",
    "\n",
    "def predict_nstar(logepss, linear_predictors, dfq):\n",
    "    X = dfq[['log(eps)']].values\n",
    "    y = dfq[['log(n)']].values\n",
    "\n",
    "    ns_pred_cv = [np.exp(lr.predict(logepss.reshape(-1, 1)).reshape(-1)) for lr in linear_predictors]\n",
    "    \n",
    "    ns_pred = np.exp(LinearRegression().fit(X, y).predict(logepss.reshape(-1, 1)).reshape(-1))\n",
    "    \n",
    "    nstar_cv = [pred[np.argmax(logepss > np.log(EPS))] for pred in ns_pred_cv if not np.all(pred == 0)]\n",
    "    \n",
    "    nstar = ns_pred[np.argmax(logepss > np.log(EPS))]\n",
    "    \n",
    "    nstar_lower, nstar_upper = np.quantile(nstar_cv, [0.05, 0.95])\n",
    "\n",
    "    return ns_pred, ns_pred_cv, nstar, nstar_lower, nstar_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we plot the our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generalizability_and_quantiles(dfy, dfq, logepss, ns_pred, ns_pred_cv, mmds, qs, nstar, nstar_upper, nstar_lower):\n",
    "    # Create figure and axes\n",
    "    fig, axes = plt.subplots(2, 1, sharex=\"all\", figsize=(10, 8))\n",
    "\n",
    "    # Generalizability plot\n",
    "    ax = axes[0]\n",
    "    sns.lineplot(data=dfy, x=\"log(eps)\", y=\"generalizability\", hue=\"n\", ax=ax, palette=palette)\n",
    "    ax.hlines(ALPHA, ls=\"--\", xmin=np.min(logepss), xmax=np.max(logepss), color=\"black\")\n",
    "    for n in mmds.keys():\n",
    "        ax.vlines(qs[n], ymin=0, ymax=ALPHA, ls=\":\")\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    # Quantiles plot\n",
    "    ax = axes[1]\n",
    "    ymax = max(ns_pred)\n",
    "    sns.lineplot(data=dfq, x=\"log(eps)\", y=\"n\", ax=ax, ls=\"\", marker=\"o\", hue=\"n\", legend=False)\n",
    "    for n in mmds.keys():\n",
    "        ax.vlines(qs[n], ymin=n, ymax=ymax, ls=\":\")\n",
    "    ax.vlines(np.log(EPS), ymin=0.1, ymax=ymax, color=\"black\", ls=\"--\")\n",
    "    sns.lineplot(x=logepss, y=ns_pred, color=\"green\", ls=\"-.\", ax=ax)\n",
    "    for it, ns_tmp in enumerate(ns_pred_cv):\n",
    "        if np.max(ns_tmp) > 1000:\n",
    "            continue\n",
    "        sns.lineplot(x=logepss, y=ns_tmp, color=\"green\", ls=\"-.\", alpha=0.5, ax=ax)\n",
    "\n",
    "    # N* Lines\n",
    "    ax.hlines(nstar, xmin=np.min(logepss), xmax=np.log(EPS), ls=\"-\", color=\"red\")\n",
    "    ax.hlines(nstar_upper, xmin=np.min(logepss), xmax=np.log(EPS), ls=\"-\", color=\"red\", alpha=0.3)\n",
    "    ax.hlines(nstar_lower, xmin=np.min(logepss), xmax=np.log(EPS), ls=\"-\", color=\"red\", alpha=0.3)\n",
    "    ax.set_yscale(\"log\")\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    # Finalize and save\n",
    "    fig.suptitle(f\"Generalizability for N = {len(ecs):02d}\\n\"\n",
    "                 f\"n*(alpha={ALPHA}, eps={EPS}) = {np.ceil(nstar)}\\n\"\n",
    "                 f\"{LR_CONFIDENCE} confidence interval: [{np.ceil(nstar_lower)}, {np.ceil(nstar_upper)}]\")\n",
    "    plt.tight_layout()\n",
    "    if FORMAT == \"pdf\":\n",
    "        plt.savefig(EXP2_DIR / f\"N={len(ecs):02d}.pdf\")\n",
    "    else:\n",
    "        plt.savefig(EXP2_DIR / f\"N={len(ecs):02d}.png\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = (len(ec_pool) + 9) // 10\n",
    "\n",
    "for _ in tqdm(\n",
    "    range(total_iterations)):\n",
    "    # -- Sample new rankings from ec pool\n",
    "    ecs, ec_pool, rankings, nv = sample_and_compute_rankings(ecs, ec_pool, rv)\n",
    "\n",
    "    # -- Compute the lower bound\n",
    "    variance, var_lower_bound = compute_variance_and_lower_bound(rankings)\n",
    "\n",
    "    # -- Compute mmds\n",
    "    mmds = calculate_mmds(rankings, nv)\n",
    "\n",
    "    # -- Compute generalizability and quantiles\n",
    "\n",
    "    # Prepare log(eps) scale\n",
    "    logepss = np.linspace(np.log(EPS) - 0.1, np.log(max(np.quantile(mmde, ALPHA) for mmde in mmds.values())) + 0.1, 1000)\n",
    "\n",
    "    # Dataframe for generalizability\n",
    "    dfy = create_generalizability_dataframe(mmds, logepss)\n",
    "\n",
    "    # Dataframe for quantiles\n",
    "    qs, dfq = create_quantiles_dataframe(mmds)\n",
    "\n",
    "    # Linear Regression with Cross-Validation\n",
    "    linear_predictors, residuals = perform_linear_regression_with_cv(dfq)\n",
    "    \n",
    "    # Predictions\n",
    "    ns_pred, ns_pred_cv, nstar, nstar_lower, nstar_upper = predict_nstar(logepss, linear_predictors, dfq)\n",
    "\n",
    "    # -- Plotting\n",
    "    plot_generalizability_and_quantiles(dfy, dfq, logepss, ns_pred, ns_pred_cv, mmds, qs, nstar, nstar_upper, nstar_lower)\n",
    "\n",
    "    out.append({\n",
    "        \"kernel\": KERNELNAME,\n",
    "        \"alpha\": ALPHA,\n",
    "        \"eps\": EPS,\n",
    "        \"disjoint\": DISJOINT,\n",
    "        \"replace\": REPLACE,\n",
    "        \"N\": len(ecs),\n",
    "        \"nstar\": nstar,\n",
    "        \"nstar_lower\": nstar_lower,\n",
    "        \"nstar_upper\": nstar_upper,\n",
    "        \"variance\": variance,\n",
    "        \"var_lower_bound\": var_lower_bound,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we generate a gif to show the changes when changing `n`. Also, we store the outputs to a file for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "if FORMAT == \"gif\":\n",
    "    images = [iio.imread(image) for image in glob.glob(str(EXP2_DIR / \"*.png\"))]\n",
    "    iio.mimwrite(EXP2_DIR / f\"nstar.gif\", images, duration=750,\n",
    "                    loop=0)\n",
    "\n",
    "# -- Store nstar predictions\n",
    "out = pd.DataFrame(out)\n",
    "out.to_parquet(EXP2_DIR / \"nstar.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
