# Paths for the outputs.
paths:
  outputs_dir: outputs
  figures_dir: figures

# Parameters for the ProjectManager
project_parameters:
  name: "Encoders"
  load_precomputed_mmd: True
  dump_results: True
  delete_existing_results: False
  verbose: True

# Parameters for the generalizability study:
  # alpha specifies the desired level of generalizability;
  # delta is used to set a condition on the minimum desired value of the kernel
    # borda: max difference in relative position of 'idx' for two rankings to be similar
    # jaccard: minimum intersection over union between top-k tiers for two rankings to be similar
    # mallows: max fraction of discordant pairs for two rankings to be similar
  # seed is the random seed passed to np.random.default_rng
  # rep is the number of pairs of subsamples used to estimate the distribution of the MMD
  # tol_missing_alternatives: maximum allowed fraction of missing alternatives for a condition to be kept
    # e.g., if tol_missing_alternatives = 0.2: if an experiment evaluates 7/10 alternatives, it is filtered out from the analysis
  # tol_missing_conditions: maximum allowed fraction of missing experiments for an alternative to be kept
  # e.g., if tol_missing_conditions = 0.2: if an alternative is evaluated in 78/100 experiments, it is filtered out from the analysis
  # Nmax is the maximum size of the simulated preliminary study (sample size to compute n-generalizability)
    # set to `null` to impose no upper boundary
# The other defining parameter for a generalizability analysis, delta, is defined for every kernel differently,
# as it has different interpretations (see below).
parameters:
  alpha:
    - 0.7
    - 0.8
    - 0.9
    - 0.95
    - 0.99
  delta:
    - 0.01
    - 0.05
    - 0.1
    - 0.2
    - 0.3
  seed: 37
  rep: 200
  tol_missing_alternatives: 0.2
  tol_missing_conditions: 0.2
  Nmax: 100

# The following entries define the data and how to interpret it.
    # the dataset is stored in dataset_path. Its primary key consists of the experimental factors + alternatives.

  # An experimental factor is a variable that influences the outcome of an experiment. We distinguish three kinds:
    # held-constant factors: fixed to a specified level.
      # factor_name: level_name
    # design factors: an independent generalizability analysis for every combination of levels of design factors
      # factor_name: "_all"
    # generalizability the factor for which we want to draw generalizable conclusions.
      # factor_name: null

  # target: the name of the column, the alternatives are ranked according to it.
  # alternatives the name of the column listed the compared methods
  # target_is_error: set to False if the target column contains a score (e.g., as output of sklearn.metrics.accuracy_score),
    # to True if it contains an error (e.g., as output of sklearn.metrics.mean_squared_error). If the results contain multiple metrics,
    # they ALL HAVE TO BE EITHER SCORES OR ERRORS
data:
  dataset_path: data/encoders_results.parquet
  alternatives_col_name: "encoder"
  experimental_factors_name_lvl:
    dataset: null
    model: "_all"
    tuning: "_all"
    scoring: "_all"
  target_col_name: "cv_score"
  target_is_error: False

# Parameteres controlling the iid sampling from valid experimental conditions, to approximate the
# true distribution of results and compute the MMD between pairs of studies.
# disjoint and replace are ignored if the method passed to pm.generalizability_analysis is "approximation"
  # sample_size: increment in sample size N
  # disjoint: if True, compute MMD on two disjoint samples of experimental conditions
  # replace: if True, compute MMD on two samples of experimental conditions, with replacement
# We interpret combinations of disjoint and replace as follows:
  # disjoint = true, replace = true: pessimistic setting, MMD is biased upwardly and generalizability downwardly
  # disjoint = true, replace = false: realistic setting, no duplicate conditions
  # disjoint = false, replace = false: optimistic setting, MMD is biased downwardly and generalizability upwardly
  # disjoint = false, replace = true: --- setting, without clear biases
sampling:
  sample_size: 10
  disjoint: true
  replace: false


# How the predicted number of necessary experiments nstar is computed. The estimation is always made by estimating the
# ICDF (inverse CDF, or quantile function) of the MMD. The estimation methods are used by a RankingKernel object.
#  As such, the implementation of the kernel should have hte appropriate methods. More details are in kernels.py.
#  Possible values:
  # approximation (almost instant): based on a close-formula approximating the ICDF of the MMD
  # naive (VERY slow, deprecated if other methods are available): get a pair of samples of results, compute their MMD, estimate the ICDF of the MMD.
  # vectorized (slow): get multiple pairs of samples of results and compute their MMD in one function call.
  # embedding (fast, recommended): use an equivalent definition of the MMD to speed up the estimation
nstar_estimation_methods:
  rankings:
    - "approximation"
    - "embedding"
  vectors:
    - "naive"
    - "approximation"

# Each kernel corresponds to a goal of the study.
  # kernel: the name of a subclass of genexpy.kernels.base.Kernel
  # params: the parameters of a kernel as defined in kernels.py. A list of values
kernels:

  - name: "BordaKernel"
    params:
      alternative: # alternative of interest
        - "OHE"
      nu:
        - "auto"                  # kernel bandwidth, auto = 1 /  na

  - name: "JaccardKernel"
    params:
      k:                          # number of top tiers considered
        - 1

  - name: "MallowsKernel"
    params:
      nu:                         # kernel bandwidth, auto = 1 /  binom(na, 2)
        - "auto"

  - name: "RBFKernel"
    params:
      gamma:
        - "auto"                  # kernel bandwidth, auto = 1 / na
