# Paths for the outputs.
paths:
  outputs_dir: outputs
  figures_dir: figures

# Parameters for the generalizability study:
  # alpha specifies the desired level of generalizability;
  # delta is used to set a condition on the minimum desired value of the kernel
    # borda: max difference in relative position of 'idx' for two rankings to be similar
    # jaccard: minimum intersection over union between top-k tiers for two rankings to be similar
    # mallows: max fraction of discordant pairs for two rankings to be similar
  # seed is hte random seed passed to np.random.default_rng
  # rep is the number of pairs of subsamples used to estimate the distribution of the MMD
# The other defining parameter for a generalizability analysis, delta, is defined for every kernel differently,
# as it has different interpretations (see below).
parameters:
  alpha:
    - 0.7
    - 0.8
    - 0.9
    - 0.95
    - 0.99
  delta:
    - 0.01
    - 0.05
    - 0.1
    - 0.2
    - 0.3
  seed: 37
  rep: 100

# The following entries define the data and how to interpret it.
    # the dataset is stored in dataset_path. Its primary key consists of the experimental factors + alternatives.

  # An experimental factor is a variable that influences the outcome of an experiment. We distinguish three kinds:
    # held-constant factors: fixed to a specified level.
      # factor_name: level_name
    # design factors: an independent generalizability analysis for every combination of levels of design factors
      # factor_name: "_all"
    # generalizability the factor for which we want to draw generalizable conclusions.
      # factor_name: null

  # target: the name of the column, the alternatives are ranked according to it.
  # alternatives the name of the column listed the compared methods
data:
  dataset_path: data/encoders_results.parquet
  experimental_factors_name_lvl:
    dataset: null
    model: "_all"
    tuning: "no"
    scoring: "_all"
  target_col_name: "cv_score"
  alternatives_col_name: "encoder"

# Parameteres controlling the iid sampling from valid experimental conditions, to approximate the
# true distribution of results and compute the MMD between pairs of studies.
  # sample_size: increment in sample size N
  # disjoint: if True, compute MMD on two disjoint samples of experimental conditions
  # replace: if True, compute MMD on two samples of experimental conditions, with replacement
# We interpret combinations of disjoint and replace as follows:
  # disjoint = true, replace = true: pessimistic setting, MMD is biased upwardly and generalizability downwardly
  # disjoint = true, replace = false: realistic setting, no duplicate conditions
  # disjoint = false, replace = false: optimistic setting, MMD is biased downwardly and generalizability upwardly
  # disjoint = false, replace = true: --- setting, without clear biases
sampling:
  sample_size: 30
  disjoint: true
  replace: false

# Each kernel corresponds to a goal of the study.
  # kernel: the name of a Kernel object in kernels.py, within double quotation marks
  # params: the parameters of a kernel as defined in kernels.py. A list of values
  # delta: float in [0, 1], defines the similarity threshold between rankings
kernels:

  - kernel: "borda_kernel"
    class_impl: "kernels_classes.BordaKernel"
    params:
      alternative: # alternative of interest
        - "OHE"
        - "DE"
      nu:
        - "auto"                  # kernel bandwidth, auto = 1 /  na

  - kernel: "jaccard_kernel"
    class_impl: "kernels_classes.JaccardKernel"
    params:
      k:                          # number of top tiers considered
        - 1

  - kernel: "mallows_kernel"
    class_impl: "kernels_classes.MallowsKernel"
    params:
      nu:                         # kernel bandwidth, auto = 1 /  binom(na, 2)
        - "auto"
