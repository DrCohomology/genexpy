{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many subtasks are enough?\n",
    "\n",
    "As explained in the paper, given a desired generalizability $\\alpha^*$ and a similarity threshold between rankings $\\delta^*$, we show how to estimate the number of subtasks required to obtain generalizable results for a given task. \n",
    "The procedure goes as follows: \n",
    "1. Load the experimental results. \n",
    "2. Query the results for a combination of design and held-constant factors.\n",
    "3. Sample without repetition $N$ levels of the allowed-to-vary factor (`subtask_description`) and query the results accordingly. \n",
    "4. Rank the alternatives according to the target column. \n",
    "5. Estimate the $\\alpha^*$-quantile of MMD for all $n \\leq N$, call it $\\varepsilon^{\\alpha^*}_n$.\n",
    "6. Fit a linear model $\\log(n) = \\beta_1 \\log(\\varepsilon^{\\alpha^*}_n) + \\beta_0$.\n",
    "7. Estimate $n^* = \\exp(\\beta_1 \\log(\\varepsilon(\\delta^*)) + \\beta_0)$, where $\\varepsilon(\\delta^*)$ is a threshold on MMD.\n",
    "We perform most of these operations within the main loop, iterating over the combinations of design factors. \n",
    "\n",
    "We can investigate the behavior of generalizability and $n^*$ for different $\\alpha^*$ and $\\delta^*$ by changing them in `config.yaml` and re-running the notebook. \n",
    "We analyze this in `demo2_plots.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from genexpy import lower_bounds as gu\n",
    "from genexpy import kernels as ku\n",
    "from genexpy import rankings_utils as ru\n",
    "from genexpy import mmd as mmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the parameters from the configuration file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:42.457369Z",
     "start_time": "2024-08-01T09:15:42.420107Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "OUTPUT_DIR = Path(config['paths']['output_dir'])\n",
    "FIGURES_DIR = Path(config['paths']['figures_dir'])\n",
    "\n",
    "SEED = config['parameters']['seed']\n",
    "RNG = np.random.default_rng(SEED)\n",
    "ALPHA = config['parameters']['alpha']\n",
    "LR_CONFIDENCE = config['parameters']['lr_confidence']\n",
    "CI_LOWER = (1 - LR_CONFIDENCE) / 2\n",
    "CI_UPPER = LR_CONFIDENCE + CI_LOWER\n",
    "\n",
    "DATASET = Path(config['data']['dataset_path'])\n",
    "EXPERIMENTAL_FACTORS = config['data']['experimental_factors']\n",
    "TARGET = config['data']['target']\n",
    "ALTERNATIVES = config['data']['alternatives']\n",
    "\n",
    "SAMPLE_SIZE = config['sampling']['sample_size']\n",
    "DISJOINT = config['sampling']['disjoint']\n",
    "REPLACE = config['sampling']['replace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the kernels, storing them in a dictionary together with heir parameters and the specified $\\delta^*$ (one for each kernel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:42.467698Z",
     "start_time": "2024-08-01T09:15:42.457369Z"
    }
   },
   "outputs": [],
   "source": [
    "KERNELS = {}\n",
    "for kernel_config in config['kernels']:\n",
    "    kernel_func = getattr(ku, kernel_config['kernel'], None)\n",
    "    \n",
    "    if kernel_func:\n",
    "        delta = kernel_config['delta']  # to get epsilon\n",
    "        match kernel_config['kernel']:\n",
    "            case \"mallows_kernel\":\n",
    "                eps = np.sqrt(2 * (1 - np.exp(-delta)))  # assumes nu = 1/binom(n, 2)\n",
    "            case \"jaccard_kernel\":\n",
    "                eps = np.sqrt(2 * (1 - (1-delta)))\n",
    "            case \"borda_kernel\":\n",
    "                eps = np.sqrt(2 * (1 - np.exp(-delta)))   # assumes nu = 1/n\n",
    "            case _ :\n",
    "                raise ValueError(f\"The kernel {kernel_config['kernel']} must be either the Jaccard, Mallows, or Borda kernel.\")  \n",
    "\n",
    "        for param_key, param_values in kernel_config['params'].items():\n",
    "            if isinstance(param_values, list):\n",
    "                for value in param_values:\n",
    "                    params = {param_key: value}\n",
    "                    kernel_name = f\"{kernel_config['kernel']}_{param_key}_{value}\"\n",
    "                    KERNELS[kernel_name] = (kernel_func, params, eps, delta)\n",
    "            else:\n",
    "                params = {param_key: param_values}\n",
    "                kernel_name = f\"{kernel_config['kernel']}_{param_key}_{param_values}\"\n",
    "                KERNELS[kernel_name] = (kernel_func, params, eps, delta)\n",
    "    else:\n",
    "        print(f\"Kernel function '{kernel_config['kernel']}' not found in module 'kernels'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "\n",
    "First, we load the dataset of results and perform some preliminary checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:43.388938Z",
     "start_time": "2024-08-01T09:15:42.470739Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "if DATASET.suffix == '.parquet':\n",
    "    df = pd.read_parquet(DATASET)\n",
    "elif DATASET.suffix == '.csv':\n",
    "    df = pd.read_csv(DATASET)\n",
    "else:\n",
    "    raise Exception(\"Please use a Parquet or CSV file as the format of your data\")\n",
    "\n",
    "# Keep the preferred scoring only\n",
    "df = df.query(\"score_key == preferred_score\").drop(columns=[\"score_key\", \"preferred_score\"])\n",
    "\n",
    "# Check whether exactly one of the experimental factors is None \n",
    "assert sum(value is None for value in EXPERIMENTAL_FACTORS.values()) == 1, \"Exactly one experimental factor must be set to null in config.yaml.\"\n",
    "\n",
    "# Check whether the factors listed in the config coincide with the columns of df\n",
    "columns_to_check = set(EXPERIMENTAL_FACTORS.keys()).union({TARGET, ALTERNATIVES})\n",
    "if not_in_df := columns_to_check - set(df.columns):\n",
    "    raise ValueError(f\"The following columns are missing from the dataframe: {not_in_df}\")\n",
    "if not_in_config:= set(df.columns) - columns_to_check:\n",
    "    warnings.warn(f\"The following columns in the dataframe are not required: {not_in_config}\", stacklevel=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>subtask_description</th>\n",
       "      <th>number_of_shots</th>\n",
       "      <th>model_family_model_name</th>\n",
       "      <th>score_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT GPT-3 Small</td>\n",
       "      <td>0.195038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT GPT-3 Small</td>\n",
       "      <td>0.193130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>2</td>\n",
       "      <td>GPT GPT-3 Small</td>\n",
       "      <td>0.272824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>3</td>\n",
       "      <td>GPT GPT-3 Small</td>\n",
       "      <td>0.253053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>emojis_emotion_prediction</td>\n",
       "      <td>0</td>\n",
       "      <td>BIG-G T=1 2b</td>\n",
       "      <td>0.461527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449233</th>\n",
       "      <td>object_counting</td>\n",
       "      <td>object_counting</td>\n",
       "      <td>3</td>\n",
       "      <td>GPT GPT-3 3B</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449238</th>\n",
       "      <td>object_counting</td>\n",
       "      <td>object_counting</td>\n",
       "      <td>0</td>\n",
       "      <td>BIG-G T=1 128b</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449249</th>\n",
       "      <td>object_counting</td>\n",
       "      <td>object_counting</td>\n",
       "      <td>1</td>\n",
       "      <td>BIG-G T=1 128b</td>\n",
       "      <td>0.131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449260</th>\n",
       "      <td>object_counting</td>\n",
       "      <td>object_counting</td>\n",
       "      <td>2</td>\n",
       "      <td>BIG-G T=1 128b</td>\n",
       "      <td>0.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449271</th>\n",
       "      <td>object_counting</td>\n",
       "      <td>object_counting</td>\n",
       "      <td>3</td>\n",
       "      <td>BIG-G T=1 128b</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183883 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         task_name        subtask_description  \\\n",
       "2        emojis_emotion_prediction  emojis_emotion_prediction   \n",
       "6        emojis_emotion_prediction  emojis_emotion_prediction   \n",
       "10       emojis_emotion_prediction  emojis_emotion_prediction   \n",
       "14       emojis_emotion_prediction  emojis_emotion_prediction   \n",
       "18       emojis_emotion_prediction  emojis_emotion_prediction   \n",
       "...                            ...                        ...   \n",
       "1449233            object_counting            object_counting   \n",
       "1449238            object_counting            object_counting   \n",
       "1449249            object_counting            object_counting   \n",
       "1449260            object_counting            object_counting   \n",
       "1449271            object_counting            object_counting   \n",
       "\n",
       "         number_of_shots model_family_model_name  score_value  \n",
       "2                      0         GPT GPT-3 Small     0.195038  \n",
       "6                      1         GPT GPT-3 Small     0.193130  \n",
       "10                     2         GPT GPT-3 Small     0.272824  \n",
       "14                     3         GPT GPT-3 Small     0.253053  \n",
       "18                     0            BIG-G T=1 2b     0.461527  \n",
       "...                  ...                     ...          ...  \n",
       "1449233                3            GPT GPT-3 3B     0.000000  \n",
       "1449238                0          BIG-G T=1 128b     0.004000  \n",
       "1449249                1          BIG-G T=1 128b     0.131000  \n",
       "1449260                2          BIG-G T=1 128b     0.135000  \n",
       "1449271                3          BIG-G T=1 128b     0.159000  \n",
       "\n",
       "[183883 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"task_name == 'arithmetic' and number_of_shots == 2\").model_family_model_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we keep the tasks with results for at least $80\\%$ of the LLMs, and the LLMs with results on at least $80\\%$ of the remaining tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:52.106644Z",
     "start_time": "2024-08-01T09:15:43.390477Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rf \u001b[38;5;241m=\u001b[39m \u001b[43mru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rankings_from_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfactors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mEXPERIMENTAL_FACTORS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43malternatives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALTERNATIVES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlower_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpute_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m      8\u001b[0m rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mloc[:, rf\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m tol]\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\genexpy\\genexpy\\src\\rankings_utils.py:705\u001b[0m, in \u001b[0;36mget_rankings_from_df\u001b[1;34m(df, factors, alternatives, target, lower_is_better, impute_missing, verbose)\u001b[0m\n\u001b[0;32m    703\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mlist\u001b[39m(iterator))\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group, indices \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m--> 705\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43malternatives\u001b[49m\u001b[43m)\u001b[49m[target]\n\u001b[0;32m    706\u001b[0m     rankings[group] \u001b[38;5;241m=\u001b[39m rlu\u001b[38;5;241m.\u001b[39mscore2rv(score, lower_is_better\u001b[38;5;241m=\u001b[39mlower_is_better, impute_missing\u001b[38;5;241m=\u001b[39mimpute_missing)\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(rankings, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\genexpy\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:6186\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6184\u001b[0m \u001b[38;5;66;03m# use set to handle duplicate column names gracefully in case of drop\u001b[39;00m\n\u001b[0;32m   6185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(to_remove):\n\u001b[1;32m-> 6186\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   6188\u001b[0m \u001b[38;5;66;03m# clear up memory usage\u001b[39;00m\n\u001b[0;32m   6189\u001b[0m index\u001b[38;5;241m.\u001b[39m_cleanup()\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\genexpy\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:4507\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m deleted:\n\u001b[0;32m   4503\u001b[0m     \u001b[38;5;66;03m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;66;03m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[0;32m   4505\u001b[0m     \u001b[38;5;66;03m# exception:\u001b[39;00m\n\u001b[0;32m   4506\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m-> 4507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4509\u001b[0m \u001b[38;5;66;03m# delete from the caches\u001b[39;00m\n\u001b[0;32m   4510\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\genexpy\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1442\u001b[0m, in \u001b[0;36mBlockManager.idelete\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   1439\u001b[0m is_deleted[indexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m taker \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m~\u001b[39mis_deleted)\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1442\u001b[0m nbs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_inplace_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems[\u001b[38;5;241m~\u001b[39mis_deleted]\n\u001b[0;32m   1444\u001b[0m axes \u001b[38;5;241m=\u001b[39m [new_columns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m]]\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\genexpy\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:785\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    783\u001b[0m     blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs[slobj]\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 785\u001b[0m     blknos \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblknos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m     blklocs \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs, slobj, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill\n\u001b[0;32m    790\u001b[0m     )\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# When filling blknos, make sure blknos is updated before appending to\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;66;03m# blocks list, that way new blkno is exactly len(blocks).\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\genexpy\\venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\genexpy\\venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = ru.get_rankings_from_df(df.reset_index(drop=True),\n",
    "                             factors=list(EXPERIMENTAL_FACTORS.keys()),\n",
    "                             alternatives=ALTERNATIVES,\n",
    "                             target=TARGET,\n",
    "                             lower_is_better=False, impute_missing=False)\n",
    "\n",
    "tol = 0.2\n",
    "rf = rf.loc[:, rf.isna().sum(axis=0) <= rf.shape[0] * tol]\n",
    "rf = rf.loc[rf.isna().sum(axis=1) <= rf.shape[1] * tol, :]\n",
    "df = df.loc[df.set_index(list(EXPERIMENTAL_FACTORS.keys())).index.isin(rf.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we query the dataset for the specified levels of the held-constant factors and get all the combinations of levels of design factors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:52.217464Z",
     "start_time": "2024-08-01T09:15:52.107665Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# query fot the held-constant factors\n",
    "try:\n",
    "    query_string = \" and \".join(f\"{factor} == '{lvl}'\" if isinstance(lvl, str) else f\"{factor} == {lvl}\"\n",
    "                                for factor, lvl in EXPERIMENTAL_FACTORS.items()\n",
    "                                if lvl not in [None, \"_all\"])\n",
    "    df = df.query(query_string)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "# get the combinations of levels of allowed-to-vary-factors\n",
    "try:\n",
    "    groups = df.groupby([factor for factor, lvl in EXPERIMENTAL_FACTORS.items() if lvl == \"_all\"]).groups\n",
    "except ValueError:\n",
    "    groups = {\"None\": df.index}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "We now define all the functions we will need to estimate $n^*$ in the main loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating the necessary directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:52.225825Z",
     "start_time": "2024-08-01T09:15:52.217464Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_experiment_directory(kernel_name, factors, delta):\n",
    "    exp0_dir = OUTPUT_DIR / \"_\".join([f\"{key}={value}\" for key, value in factors.items() if value is not None])\n",
    "    exp1_dir = exp0_dir / f\"{kernel_name}\"\n",
    "    exp21_dir = exp1_dir / f\"nstar_N_ALPHA={ALPHA}_delta={delta}_ci={LR_CONFIDENCE}\"\n",
    "    exp21_dir.mkdir(parents=True, exist_ok=True)\n",
    "    exp22_dir = exp1_dir / \"computed_generalizability\"\n",
    "    exp22_dir.mkdir(parents=True, exist_ok=True)\n",
    "    exp23_dir = exp1_dir / \"computed_quantiles\"\n",
    "    exp23_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return exp21_dir, exp22_dir, exp23_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we sample some levels from allowed-to-vary factor, query the dataset of results, and compute the rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:52.233451Z",
     "start_time": "2024-08-01T09:15:52.225825Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_ecs(ec_pool, sample_size):\n",
    "    assert sample_size <= len(ec_pool), f\"Sample size {sample_size} is larger than |ec_pool| = {len(ec_pool)}\"\n",
    "    return RNG.choice(ec_pool, sample_size, replace=False)\n",
    "\n",
    "def compute_rankings(ecs, rank_matrix):\n",
    "    rm_ = rank_matrix.loc[:, ecs]\n",
    "    na, nv = rm_.shape\n",
    "    \n",
    "    # Generate rankings from the data\n",
    "    rankings = ru.SampleAM.from_rank_function_dataframe(rm_)\n",
    "    \n",
    "    return rankings, nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the rankings, we compute the variance and a lower bound on generalizability we build from [1] and then compute the Maximum ean Discrepancy (MMD) for pairs of samples of varying sizes $n$. \n",
    "We will use it to estimate the $\\alpha^*$-quantile $\\varepsilon^{\\alpha^*}_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:52.241092Z",
     "start_time": "2024-08-01T09:15:52.233451Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_mmd(rankings, nv, kernel, kernelargs):\n",
    "    mmds = {\n",
    "        n: mmd.subsample_mmd_distribution(\n",
    "            rankings, subsample_size=n, rep=100, use_rv=True, use_key=False,\n",
    "            seed=SEED, disjoint=DISJOINT, replace=REPLACE, kernel=kernel, **kernelargs\n",
    "        )\n",
    "        for n in range(2, min(nv // 2 + 1, 50))  # limited to 50 \n",
    "    }\n",
    "    return mmds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the samples of MMD, we calculate the generalizability and $\\alpha^*$-quantile for each $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:52.250140Z",
     "start_time": "2024-08-01T09:15:52.241092Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_generalizability_dataframe(mmds, logepss):\n",
    "    ys = {n: [mmd.generalizability(mmde, np.exp(logeps)) for logeps in logepss] for n, mmde in mmds.items()}\n",
    "    dfy = pd.DataFrame(ys, index=logepss).reset_index().melt(id_vars='index', var_name='n', value_name='generalizability')\n",
    "    dfy.rename(columns={'index': 'log(eps)'}, inplace=True)\n",
    "    dfy['n'] = dfy['n'].astype(int)\n",
    "    return dfy\n",
    "\n",
    "def create_quantiles_dataframe(mmds):\n",
    "    qs = {n: np.log(np.quantile(mmde, ALPHA)) for n, mmde in mmds.items()}\n",
    "    dfq = pd.DataFrame(list(qs.items()), columns=['n', 'log(eps)'])\n",
    "    dfq['log(n)'] = np.log(dfq['n'])\n",
    "    return dfq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit linear regression $\\log(n) = \\beta_1\\log(\\varepsilon^{\\alpha^*}_n) = \\beta_0$ and use it to predit $n^*$ with a leave-one-out confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:15:52.261044Z",
     "start_time": "2024-08-01T09:15:52.251921Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_linear_regression_with_cv(dfq):\n",
    "    # Extracting features and target from DataFrame\n",
    "    X = dfq[['log(eps)']].values\n",
    "    y = dfq[['log(n)']].values\n",
    "\n",
    "    cv = KFold(n_splits=len(y))\n",
    "    residuals, linear_predictors = [], []\n",
    "\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        lr = LinearRegression().fit(X[train_index], y[train_index])\n",
    "        predicted = lr.predict(X[test_index])\n",
    "        residuals.extend(y[test_index] - predicted)\n",
    "\n",
    "        linear_predictors.append(lr)\n",
    "\n",
    "    return linear_predictors, residuals\n",
    "\n",
    "def predict_nstar(logepss, linear_predictors, dfq, eps):\n",
    "    X = dfq[['log(eps)']].values\n",
    "    y = dfq[['log(n)']].values\n",
    "\n",
    "    ns_pred_cv = [np.exp(lr.predict(logepss.reshape(-1, 1)).reshape(-1)) for lr in linear_predictors]\n",
    "    ns_pred = np.exp(LinearRegression().fit(X, y).predict(logepss.reshape(-1, 1)).reshape(-1))\n",
    "    nstar_cv = [pred[np.argmax(logepss > np.log(eps))] for pred in ns_pred_cv if not np.all(pred == 0)]\n",
    "    nstar = ns_pred[np.argmax(logepss > np.log(eps))]\n",
    "    nstar_lower, nstar_upper = np.quantile(nstar_cv, [CI_LOWER, CI_UPPER])\n",
    "    return ns_pred, ns_pred_cv, nstar, nstar_lower, nstar_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "\n",
    "We are finally ready to run the main loop on the combinations of design factors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T09:18:43.479146Z",
     "start_time": "2024-08-01T09:17:33.700683Z"
    }
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore')\n",
    "\n",
    "start = time.time()\n",
    "for fixed_levels, idxs in tqdm(list(groups.items()), position=0, desc=\"Configurations\", leave=True):\n",
    "    \n",
    "    # Query the results for the fixed-levels\n",
    "    idf = df.loc[idxs].reset_index(drop=True)\n",
    "    if idf.empty:\n",
    "        continue\n",
    "\n",
    "    # Current levels of design and held-constant factor\n",
    "    factors_dict = {factor: lvl\n",
    "                    for factor, lvl in EXPERIMENTAL_FACTORS.items()\n",
    "                    if lvl not in [None, \"_all\"]}\n",
    "    factors_dict.update({factor: idf[factor].unique()[0] for factor, lvl in EXPERIMENTAL_FACTORS.items()\n",
    "                         if lvl == \"_all\"})\n",
    "\n",
    "    # Rank the alternatives  \n",
    "    rank_matrix = ru.get_rankings_from_df(idf, factors=list(EXPERIMENTAL_FACTORS.keys()), \n",
    "                                            alternatives=ALTERNATIVES,\n",
    "                                            target=TARGET,\n",
    "                                            lower_is_better=False, impute_missing=True)\n",
    "    # Impute the missing values\n",
    "    rank_matrix = rank_matrix.fillna(rank_matrix.max())\n",
    "\n",
    "    # Get the pool of experimental conditions to sample from (combinations of allowed-to-vary factors)\n",
    "    atv_factor = next((key for key, value in EXPERIMENTAL_FACTORS.items() if value is None), None)\n",
    "    ec_pool = idf[atv_factor].unique()\n",
    "    ecs = np.array([])\n",
    "\n",
    "    # Loop over the kernels\n",
    "    for kernelname, (kernel, kernelargs, epsstar, deltastar) in KERNELS.items():\n",
    "        \n",
    "        # Update the parameters of the Borda kernel with the index of the alternative in the dataframe of rankings (might vary)\n",
    "        if \"borda\" in kernelname:\n",
    "            kernelargs.update({\"idx\": rank_matrix.index.get_loc(kernelargs[\"alternative\"])})\n",
    "        \n",
    "        # Iteratively sample from ec_pool increasing the sample size at every iteration\n",
    "        # The sampled experimental conditions are used to approximate the distribution of true results\n",
    "        nstar_dir, gen_dir, quant_dir = create_experiment_directory(kernelname, factors_dict, epsstar)\n",
    "        out = []\n",
    "        # for i in tqdm(range(len(ec_pool) // SAMPLE_SIZE), desc=f'Using {kernelname}', leave=False):\n",
    "        for i in range(len(ec_pool) // SAMPLE_SIZE):\n",
    "\n",
    "            if (i+1)*SAMPLE_SIZE > len(ec_pool):\n",
    "                break\n",
    "            if (i+1)*SAMPLE_SIZE > 50:\n",
    "                break\n",
    "\n",
    "            # Sample new experimental conditions from ec_pool and get their rankings\n",
    "            ecs = sample_ecs(ec_pool, (i+1)*SAMPLE_SIZE)\n",
    "            rankings, nv = compute_rankings(ecs, rank_matrix)\n",
    "\n",
    "            # Compute the variance of the experimental results and get the lower bound (conservative estimate) on the distance between the sampled mean embedding and the true mean embedding in the RKHS\n",
    "            variance = ku.var(rankings, use_rv=True, kernel=kernel, **kernelargs)\n",
    "            var_lower_bound = gu.sample_mean_embedding_lowerbound(eps=epsstar, n=len(ecs), kbar=1, v=variance)\n",
    "\n",
    "            # We do not need to compute dfy and dfq again if we have already computed them for another (alphastar, deltastar)\n",
    "            if f\"dfy_{len(ecs)}\" in [x.stem for x in gen_dir.glob(\"*.parquet\")] and f\"dfmmd_{len(ecs)}\" in [x.stem for x in quant_dir.glob(\"*.parquet\")]:\n",
    "                try:\n",
    "                    dfy = pd.read_parquet(gen_dir / f\"dfy_{len(ecs)}.parquet\")\n",
    "                    dfmmd = pd.read_parquet(quant_dir / f\"dfmmd_{len(ecs)}.parquet\")\n",
    "\n",
    "                    dfq = pd.DataFrame(dfmmd.groupby(\"n\")[\"eps\"].quantile(ALPHA)).reset_index()\n",
    "                    dfq[\"log(eps)\"] = np.log(dfq[\"eps\"])\n",
    "                    dfq[\"log(n)\"] = np.log(dfq[\"n\"])\n",
    "\n",
    "                    logepss = dfy[\"log(eps)\"].unique()\n",
    "                except Exception as e:\n",
    "                    print(\"Exception thrown for the following combination of experimental conditions: \", factors_dict)\n",
    "                    raise e\n",
    "            else:\n",
    "                # Sample the distribution of MMD for varying sizes  \n",
    "                mmds = sample_mmd(rankings, nv, kernel=kernel, kernelargs=kernelargs)\n",
    "                dfmmd = pd.DataFrame(mmds).melt(var_name=\"n\", value_name=\"eps\")\n",
    "\n",
    "                # Compute generalizability and quantiles\n",
    "                logepss = np.linspace(np.log(epsstar) - 0.1, np.log(max(np.quantile(mmde, ALPHA) for mmde in mmds.values())) + 0.1, 1000) \n",
    "                dfy = create_generalizability_dataframe(mmds, logepss)\n",
    "                dfq = create_quantiles_dataframe(mmds)\n",
    "\n",
    "            # Linear regression with cross-validation\n",
    "            # If the results are singular (always the same ranking), we output nstar = 1\n",
    "            try:\n",
    "                linear_predictors, residuals = perform_linear_regression_with_cv(dfq)\n",
    "                # -- Predictions\n",
    "                ns_pred, ns_pred_cv, nstar, nstar_lower, nstar_upper = predict_nstar(logepss, linear_predictors, dfq, epsstar)\n",
    "                singular = False\n",
    "            except ValueError:\n",
    "                nstar = nstar_lower = nstar_upper = 1\n",
    "                singular = True\n",
    "\n",
    "            # Store results\n",
    "            result_dict = {\n",
    "                \"kernel\": kernelname,\n",
    "                \"alpha\": ALPHA,\n",
    "                \"eps\": epsstar,\n",
    "                \"delta\": deltastar,\n",
    "                \"disjoint\": DISJOINT,\n",
    "                \"replace\": REPLACE,\n",
    "                \"N\": len(ecs),\n",
    "                \"nstar\": nstar,\n",
    "                \"nstar_lower\": nstar_lower,\n",
    "                \"nstar_upper\": nstar_upper,\n",
    "                \"variance\": variance,\n",
    "                \"var_lower_bound\": var_lower_bound,\n",
    "                \"singular\": singular\n",
    "            }\n",
    "            result_dict.update(factors_dict)\n",
    "            out.append(result_dict)\n",
    "\n",
    "            dfy.to_parquet(gen_dir / f\"dfy_{len(ecs)}.parquet\")\n",
    "            # dfq.to_parquet(quant_dir / f\"dfq_{len(ecs)}_{ALPHA}.parquet\")  # not needed \n",
    "            dfmmd.to_parquet(quant_dir / f\"dfmmd_{len(ecs)}.parquet\")\n",
    "\n",
    "        # Store nstar predictions\n",
    "        out = pd.DataFrame(out)\n",
    "        out.to_parquet(nstar_dir / \"nstar.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Wolfer, Geoffrey, and Pierre Alquier. *Variance-aware estimation of kernel mean embedding.* arXiv preprint arXiv:2210.06672 (2022)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
