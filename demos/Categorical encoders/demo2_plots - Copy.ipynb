{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of generalizability and $n^*$\n",
    "\n",
    "This notebook analyzes the results of `demo1_estimate_nstar.ipynb` to investigate the dependency between the desired generalizability $\\alpha^*$, the similarity threshold for rankings $\\delta^*$, and the number of experimental conditions that guarantee generalizable results $n^*$. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports and configuration"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T09:59:37.201471Z",
     "start_time": "2025-03-06T09:59:37.063771Z"
    }
   },
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we load the parameters from the configuration file. "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T09:59:37.216812Z",
     "start_time": "2025-03-06T09:59:37.202834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"config.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "OUTPUT_DIR = Path(config['paths']['output_dir'])\n",
    "FIGURES_DIR = Path(config['paths']['figures_dir'])\n",
    "FIGURES_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "DATASET = Path(config['data']['dataset_path'])\n",
    "EXPERIMENTAL_FACTORS = config['data']['experimental_factors']\n",
    "TARGET = config['data']['target']\n",
    "ALTERNATIVES = config['data']['alternatives']"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading \n",
    "\n",
    "We concatenate all of the output dataframes and add a column with the number of datasets we have results on, conditioned on (model, tuning, scoring). In the terminology of the paper, we fix the held-constant and design factors and count the number of levels of the allowed-to-vary factor. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_nstar = pd.concat([pd.read_parquet(x) \n",
    "                      for x in tqdm(list(OUTPUT_DIR.glob(\"**/**/**/nstar.parquet\")), \n",
    "                                    desc=\"Loading dataframes\")]).reset_index(drop=True)\n",
    "\n",
    "fixed_factors = [factor for factor, lvl in EXPERIMENTAL_FACTORS.items() if lvl == \"_all\"]  \n",
    "df_nstar = df_nstar.join(df_nstar.groupby(fixed_factors)[\"N\"].max(), on=fixed_factors, rsuffix=\"max\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T09:59:57.705998Z",
     "start_time": "2025-03-06T09:59:37.218834Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Plot parameters",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set(style=\"ticks\", context=\"paper\", font=\"times new roman\")\n",
    "\n",
    "# mpl.use(\"TkAgg\")\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r\"\"\"\n",
    "    \\usepackage{mathptmx}\n",
    "    \\usepackage{amsmath}\n",
    "\"\"\"\n",
    "mpl.rc('font', family='Times New Roman')\n",
    "\n",
    "# pretty names\n",
    "pc = {\"alpha\": r\"$\\alpha^*$\", \"eps\": r\"$\\varepsilon^*$\", \"nstar\": r\"$n^*$\", \"delta\": r\"$\\delta^*$\", \"N\": r\"$N$\", \"nstar_absrel_error\": \"relative error\", \"aq\": r\"$\\varepsilon^\\alpha_n$\", \"n\": r\"$n$\"}  # columns\n",
    "pk = {\"borda_kernel_idx_OHE\": r\"$\\kappa_b^{\\text{OHE}, 1/n}$\", \"mallows_kernel_nu_auto\": r\"$\\kappa_m^{1/\\binom{n}{2}}$\", \"jaccard_kernel_k_1\": r\"$\\kappa_j^{1}$\"}  # kernels\n",
    "pk.update({\"borda_kernel_idx_OHE\": \"$g_1$\", \"mallows_kernel_nu_auto\": \"$g_3$\", \"jaccard_kernel_k_1\": \"$g_2$\"})  # rename to goal_1, 2, 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T09:59:57.714040Z",
     "start_time": "2025-03-06T09:59:57.707013Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The following function outputs a very conservative upper bound for $n^*$.",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@np.vectorize\n",
    "def theoretical_nstar(alphastar, epsstar, kbar=1):\n",
    "    beta1 = -2\n",
    "    beta0 = 2*np.log(np.sqrt(2*kbar) + np.sqrt(-4*kbar * np.log(1-alphastar)))\n",
    "    return np.exp(beta0 + beta1*np.log(epsstar))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T09:59:57.724683Z",
     "start_time": "2025-03-06T09:59:57.715583Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How $n^*$ depends on $\\alpha^*$ and $\\delta^*$\n",
    "\n",
    "We can finally visualize how $n^*$ depends on $\\alpha^*$ and $\\delta^*$. \n",
    "To do so, we first fix $a\\alpha^* = 0.05$ and then $\\delta^* = 0.05$ (corresponding to $\\varepsilon(\\delta^*) \\approx 0.31$)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "alpha_fixed = 0.95\n",
    "delta_fixed = 0.05\n",
    "eps_fixed = 0.31\n",
    "\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(5.5, 5.5/2.5), width_ratios=(1, 1), sharey=True)\n",
    "\n",
    "# ----  ALPHA\n",
    "ax = axes[0]\n",
    "dfplot = df_nstar.loc[(df_nstar[\"delta\"] == delta_fixed) & (df_nstar[\"N\"] == df_nstar[\"Nmax\"])]\n",
    "\n",
    "# Make dfplot pretty\n",
    "dfplot = dfplot.rename(columns=pc)\n",
    "dfplot[\"kernel\"] = dfplot[\"kernel\"].map(pk)\n",
    "dfplot[\"nstar_th\"] = theoretical_nstar(dfplot[pc[\"alpha\"]], dfplot[pc[\"eps\"]], kbar=1)\n",
    "\n",
    "# Plot\n",
    "sns.boxplot(dfplot, x=pc[\"alpha\"], y=pc[\"nstar\"], ax=ax, hue=\"kernel\", showfliers=False, palette=\"cubehelix\",\n",
    "            dodge=True, native_scale=True, fill=False, legend=False,\n",
    "            width=0.75, boxprops={\"linewidth\": 1.2}, gap=0.25)\n",
    "# ax.set(xticks=[0.7, 0.8, 0.9, 0.99])\n",
    "ax.grid(color=\"grey\", alpha=0.2)\n",
    "\n",
    "# Uncomment to plot the conservative estimate for nstar\n",
    "# alphas = np.linspace(dfplot[pc[\"alpha\"]].min(), dfplot[pc[\"alpha\"]].max(), 100)\n",
    "# nstars_th = theoretical_nstar(alphas, eps_fixed)\n",
    "# sns.lineplot(x=alphas, y=nstars_th, ax=ax, c=\"black\", linewidth=0.5)  \n",
    "\n",
    "# ----  DELTA\n",
    "ax = axes[1]\n",
    "dfplot = df_nstar.loc[(df_nstar[\"alpha\"] == alpha_fixed) & (df_nstar[\"N\"] == df_nstar[\"Nmax\"])]\n",
    "\n",
    "# Make dfplot pretty\n",
    "dfplot = dfplot.rename(columns=pc)\n",
    "dfplot[\"kernel\"] = dfplot[\"kernel\"].map(pk)\n",
    "\n",
    "# plot\n",
    "sns.boxplot(dfplot, x=pc[\"delta\"], y=pc[\"nstar\"], ax=ax, hue=\"kernel\", showfliers=False, palette=\"cubehelix\",\n",
    "            dodge=True, native_scale=True, fill=False, legend=True,\n",
    "            width=0.75, boxprops={\"linewidth\": 1.2}, gap=0.25)\n",
    "# ax.set(xticks=[0.01, 0.1, 0.2, 0.3])\n",
    "ax.grid(color=\"grey\", alpha=0.2)\n",
    "\n",
    "# Uncomment to plot the conservative estimate for nstar\n",
    "# epss = np.linspace(dfplot[pc[\"eps\"]].min(), dfplot[pc[\"eps\"]].max(), 100)\n",
    "# nstars_th = theoretical_nstar(alpha_fixed, epss)\n",
    "# # sns.lineplot(x=epss, y=nstars_th, ax=ax, c=\"black\", linewidth=0.5) \n",
    "\n",
    "ax.legend(*ax.get_legend_handles_labels()).get_frame().set_edgecolor(\"w\")\n",
    "\n",
    "sns.despine(right=True, top=True)\n",
    "plt.tight_layout(pad=.5)\n",
    "plt.subplots_adjust(wspace=.12)\n",
    "plt.savefig(FIGURES_DIR / \"encoders_nstar_alpha_delta.pdf\")\n",
    "# plt.savefig(FIGURES_DIR / \"encoders_nstar_alpha_delta_upperbound.pdf\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:01.551194Z",
     "start_time": "2025-03-06T09:59:57.726297Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Most and least generalizable combinations of design factors",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "kernel = \"jaccard_kernel_k_1\"\n",
    "\n",
    "df_ = df_nstar.query(\"kernel==@kernel and alpha==@alpha_fixed and delta==@delta_fixed\")\n",
    "df_ = df_.loc[df_[\"N\"] == df_[\"Nmax\"]]\n",
    "df_.loc[(df_[\"nstar\"] == df_[\"nstar\"].min()) | (df_[\"nstar\"] == df_[\"nstar\"].max())]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:01.594894Z",
     "start_time": "2025-03-06T10:00:01.554210Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How $n^*$ depends on $N$\n",
    "\n",
    "We estimate the $(\\alpha^*, \\delta^*)$-generalizability on a sample of $N$ results.\n",
    "This section shows how the estimate of $n^*$ changes with bigger samples.\n",
    "In particular, we want to know how large $N$ should be to get an estimate for $n^*$ which is \"close enough\" to the estimate we get at $N=50$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "nstar_50 = df_nstar.loc[df_nstar[\"N\"] == df_nstar[\"Nmax\"]].drop(columns=[\"N\", \"Nmax\"])\n",
    "keys = [\"kernel\", \"alpha\", \"eps\", \"model\", \"tuning\", \"scoring\"]\n",
    "df_ = pd.merge(df_nstar, nstar_50, left_on=keys, right_on=keys, suffixes=(\"\", \"_true\"))[keys + [\"nstar\", \"nstar_true\", \"N\", \"Nmax\"]]\n",
    "df_[\"nstar_error\"] = df_[\"nstar\"] - df_[\"nstar_true\"]\n",
    "df_[\"nstar_relative_error\"] = (df_[\"nstar\"] - df_[\"nstar_true\"]) / df_[\"nstar_true\"]\n",
    "df_[\"nstar_absolute_error\"] = np.abs(df_[\"nstar\"] - df_[\"nstar_true\"])\n",
    "df_[\"nstar_absrel_error\"] = np.abs(df_[\"nstar\"] - df_[\"nstar_true\"]) / df_[\"nstar_true\"]\n",
    "# df_ = df_.loc[df_[\"N\"] != df_[\"Nmax\"]]\n",
    "df_ = df_.query(\"Nmax == 50\")\n",
    "\n",
    "dfplot = df_.copy().query(\"N < Nmax\").rename(columns=pc)\n",
    "dfplot[\"kernel\"] = dfplot[\"kernel\"].map(pk)\n",
    "\n",
    "y = pc[\"nstar_absrel_error\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:01.636660Z",
     "start_time": "2025-03-06T10:00:01.596904Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:03.104591Z",
     "start_time": "2025-03-06T10:00:01.639694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5.5/2, 2))\n",
    "\n",
    "sns.boxplot(dfplot, x=pc[\"N\"], y=y, showfliers=False, fliersize=0.3, hue=\"kernel\", palette=\"cubehelix\", ax=ax, legend=True, linewidth=1.2, fill=False, gap=0.2)  \n",
    "\n",
    "ax.grid(color=\"grey\", alpha=.2)\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "ax.legend(*ax.get_legend_handles_labels()).get_frame().set_edgecolor(\"w\")\n",
    "sns.despine()\n",
    "plt.tight_layout(pad=.5)\n",
    "\n",
    "plt.savefig(FIGURES_DIR / \"encoders_nstar_absrel_error.pdf\")\n",
    "plt.show()"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## True $n^*$ estimate error\n",
    "\n",
    "We estimate the $(\\alpha^*, \\delta^*)$-generalizability on a sample of $N$ results.\n",
    "This section shows how the estimate of $n^*$ changes with bigger samples.\n",
    "In particular, we want to know how large $N$ should be to get an estimate for $n^*$ which is \"close enough\" to the estimate we get at $N=50$."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:03.152999Z",
     "start_time": "2025-03-06T10:00:03.110643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nstar_50 = df_nstar.loc[df_nstar[\"N\"] == df_nstar[\"Nmax\"]].drop(columns=[\"N\", \"Nmax\"])\n",
    "keys = [\"kernel\", \"alpha\", \"eps\", \"model\", \"tuning\", \"scoring\"]\n",
    "df_ = pd.merge(df_nstar, nstar_50, left_on=keys, right_on=keys, suffixes=(\"\", \"_true\"))[keys + [\"nstar\", \"nstar_true\", \"N\", \"Nmax\"]]\n",
    "df_[\"nstar_error\"] = df_[\"nstar\"] - df_[\"nstar_true\"]\n",
    "df_[\"nstar_relative_error\"] = (df_[\"nstar\"] - df_[\"nstar_true\"]) / df_[\"nstar_true\"]\n",
    "df_[\"nstar_absolute_error\"] = np.abs(df_[\"nstar\"] - df_[\"nstar_true\"])\n",
    "df_[\"nstar_absrel_error\"] = np.abs(df_[\"nstar\"] - df_[\"nstar_true\"]) / df_[\"nstar_true\"]\n",
    "# df_ = df_.loc[df_[\"N\"] != df_[\"Nmax\"]]\n",
    "df_ = df_.query(\"Nmax == 50\")\n",
    "\n",
    "dfplot = df_.copy().query(\"N < Nmax\").rename(columns=pc)\n",
    "dfplot[\"kernel\"] = dfplot[\"kernel\"].map(pk)\n",
    "\n",
    "y = pc[\"nstar_absrel_error\"]"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:25.845971Z",
     "start_time": "2025-03-06T10:00:03.154008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_nstar = pd.concat([pd.read_parquet(x) \n",
    "                      for x in tqdm(list(OUTPUT_DIR.glob(\"**/**/**/nstar.parquet\")), \n",
    "                                    desc=\"Loading dataframes\")]).reset_index(drop=True)\n",
    "\n",
    "fixed_factors = [factor for factor, lvl in EXPERIMENTAL_FACTORS.items() if lvl == \"_all\"]  \n",
    "df_nstar = df_nstar.join(df_nstar.groupby(fixed_factors)[\"N\"].max(), on=fixed_factors, rsuffix=\"max\")"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Illustrative Example: Algorithm to predict $n^*$\n",
    "\n",
    "The following cell provides a representation of the algorithm to estimate $n^*$. \n",
    "First of all, we show it for the combination `model=DTC` (Decision Tree), `tuning=no` (No tuning), `scoring=AUC` (Area Under the ROC).\n",
    "\n",
    "First, we fix $\\alpha^*$, $\\delta^*$ and the kernel (Mallows kernel in this case).\n",
    "Second, take the distribution of the MMD (for varying sample sizes $n$) and compute the $\\alpha^*$-quantile.   "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:26.033768Z",
     "start_time": "2025-03-06T10:00:25.848986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = \"LR\"\n",
    "tuning = \"no\"\n",
    "scoring = \"ACC\"\n",
    "\n",
    "kernelname = \"mallows_kernel_nu_auto\"\n",
    "N = 50  # size of preliminary experiments\n",
    "alpha = 0.95\n",
    "eps = 0.1\n",
    "\n",
    "OUTPUT_MMD_DIR = OUTPUT_DIR / f\"model={model}_tuning={tuning}_scoring={scoring}\" / kernelname\n",
    "pc.update({\"generalizability\": r\"$n$-Gen\"})\n",
    "\n",
    "dfq = pd.read_parquet(OUTPUT_MMD_DIR / \"computed_quantiles\" / f\"dfmmd_{N}.parquet\")  # contains the distribution of the n-MMD \n",
    "dfy = pd.read_parquet(OUTPUT_MMD_DIR / \"computed_generalizability\" / f\"dfy_{N}.parquet\")\n",
    "dfy[\"eps\"] = np.exp(dfy[\"log(eps)\"])\n",
    "alpha_quantiles = {n: np.quantile(np.quantile(dfq.query(\"n == @n\")[\"eps\"], alpha, method=\"linear\"), alpha) for n in dfq[\"n\"].unique()}\n",
    "dfaq = pd.DataFrame(alpha_quantiles, index=[0]).melt(var_name=\"n\", value_name=\"aq\").rename(columns=pc)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:00:33.206761Z",
     "start_time": "2025-03-06T10:00:26.038794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "plt.close(\"all\")\n",
    "\n",
    "palette=\"crest_r\"\n",
    "lw = 0.5\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(2.5, 4), sharex=True)\n",
    "\n",
    "# -- Generalizability\n",
    "ax = axes[0]\n",
    "ax.set_xscale(\"log\")\n",
    "sns.lineplot(dfy.rename(columns=pc), x=pc[\"eps\"], y=pc[\"generalizability\"], hue=pc[\"n\"], palette=palette, ax=ax, legend=False)\n",
    "\n",
    "# Quantile lines\n",
    "# for (n, laq), color in zip(alpha_quantiles.items(), sns.color_palette(palette, n_colors=len(alpha_quantiles))):\n",
    "#     ax.vlines(laq, ymin=0, ymax=alpha, ls=\"-\", color=color, lw=lw)\n",
    "    # ax.axvline(laq, ymin=-1.2, ymax=0, ls=\":\", color=color, lw=lw, zorder=-1, clip_on=False)\n",
    "ax.axhline(alpha, color=\"black\", ls=\"--\", lw=lw)\n",
    "ax.axvline(eps, color=\"black\", ls=\"--\", lw=lw)\n",
    "\n",
    "# -- Quantiles for regression\n",
    "ax = axes[1]\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "sns.lineplot(dfaq, x=pc[\"aq\"], y=pc[\"n\"], ax=ax, ls=\"\", marker=\"o\", hue=pc[\"n\"], legend=False, palette=palette)\n",
    "\n",
    "# Linear regression\n",
    "X = np.log(dfaq[pc[\"aq\"]]).to_numpy().reshape(-1, 1)\n",
    "y = np.log(dfaq[pc[\"n\"]]).to_numpy().reshape(-1, 1)\n",
    "\n",
    "padding = 1.1\n",
    "epss = np.linspace(eps / padding, np.max(dfq[\"eps\"]) * padding, 1000)\n",
    "lr = LinearRegression().fit(X, y)\n",
    "ns_pred = np.exp(lr.predict(np.log(epss).reshape(-1, 1)).reshape(1, -1)[0])\n",
    "nstar = int(ns_pred[np.argmin(np.abs(epss - eps))])\n",
    "ax.plot(epss, ns_pred, ls=\"--\", color=\"grey\", lw=lw)\n",
    "\n",
    "# Quantile lines\n",
    "# for (n, aq), color in zip(alpha_quantiles.items(), sns.color_palette(palette, n_colors=len(alpha_quantiles))):\n",
    "#     ax.vlines(aq, ymin=n, ymax=nstar, ls=\"-\", color=color, lw=lw)\n",
    "    # ax.axvline(aq, ymin=1, ymax=1.2, ls=\":\", color=color, lw=lw, zorder=-1, clip_on=False)\n",
    "ax.axvline(eps, color=\"black\", ls=\"--\", lw=lw)\n",
    "\n",
    "# - General formatting\n",
    "sns.despine(top=True, right=True)\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "\n",
    "plt.savefig(FIGURES_DIR / f\"encoders_nstar_prediction_N={N}.pdf\")\n",
    "plt.show()"
   ],
   "execution_count": 13,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
