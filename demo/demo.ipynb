{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of core features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some imports and some plot settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio.v2 as iio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from collections import defaultdict\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from numpy.random import Generator\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from genexpy import lower_bounds as gu\n",
    "from genexpy import kernels as ku\n",
    "from genexpy import probability_distributions as prob\n",
    "from genexpy import rankings_utils as ru\n",
    "from genexpy import mmd as mmd\n",
    "\n",
    "mpl.use(\"TkAgg\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"notebook\")\n",
    "palette = \"flare_r\"\n",
    "sns.set_palette(\"flare_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the hyperparameters from the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "FIGURES_DIR = Path(config['paths']['figures_dir'])\n",
    "\n",
    "FORMAT = config['format']['output']\n",
    "\n",
    "SEED = config['parameters']['seed']\n",
    "RNG = np.random.default_rng(SEED)\n",
    "EPS = config['parameters']['epsilon']\n",
    "ALPHA = config['parameters']['alpha']\n",
    "LR_CONFIDENCE = config['parameters']['lr_confidence']\n",
    "CI_LOWER = (1 - LR_CONFIDENCE) / 2\n",
    "CI_UPPER = LR_CONFIDENCE + CI_LOWER\n",
    "\n",
    "DATASET = Path(config['data']['dataset_path'])\n",
    "EXPERIMENTAL_FACTORS = config['data']['experimental_factors']\n",
    "TARGET = config['data']['target']\n",
    "ALTERNATIVES = config['data']['alternatives']\n",
    "\n",
    "SAMPLE_SIZE = config['sampling']['sample_size']\n",
    "DISJOINT = config['sampling']['disjoint']\n",
    "REPLACE = config['sampling']['replace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the dataset into a pandas dataframe and we check that only one experimental factor is set to `None`, indicating that it is allowed to vary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET.suffix == '.parquet':\n",
    "    df = pd.read_parquet(DATASET).drop(columns=[\"time\"])\n",
    "elif DATASET.suffix == '.csv':\n",
    "    df = pd.read_csv(DATASET).drop(columns=[\"time\"])\n",
    "else:\n",
    "    raise Exception(\"Please use a Parquet or CSV file as the format of your data\")\n",
    "\n",
    "# Check whether exactly one of the experimental factors is None \n",
    "assert sum(value is None for value in EXPERIMENTAL_FACTORS.values()) == 1, \"Exactly one experimental factor must be None\"\n",
    "\n",
    "columns_to_check = set(EXPERIMENTAL_FACTORS.keys()).union({TARGET, ALTERNATIVES})\n",
    "# Check whether the factors listed in the config actually exist in the df\n",
    "if not_in_df := columns_to_check - set(df.columns):\n",
    "    raise ValueError(f\"The following columns are missing from the dataframe: {not_in_df}\")\n",
    "\n",
    "# Check whether the factors listed in the config are exhaustive\n",
    "if not_in_config:= set(df.columns) - columns_to_check:\n",
    "    raise ValueError(f\"The following columns in the dataframe are not required: {not_in_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build a query from the experimental factors and convert the `df` to a rank matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \" and \".join(f\"{key} == '{value}'\" if isinstance(value, str) else f\"{key} == {value}\"\n",
    "                            for key, value in EXPERIMENTAL_FACTORS.items() if value is not None)\n",
    "\n",
    "df = df.query(query_string).reset_index(drop=True)\n",
    "rank_matrix = ru.get_rankings_from_df(df, factors=list(EXPERIMENTAL_FACTORS.keys()), alternatives=ALTERNATIVES,\n",
    "                             target=TARGET,\n",
    "                             lower_is_better=False, impute_missing=True)\n",
    "rank_matrix = rank_matrix.fillna(rank_matrix.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define some kernels that can be used for MMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Config\n",
    "\n",
    "kernels = {}\n",
    "for kernel_name, settings in config['kernels'].items():\n",
    "    # Fetch the kernel function dynamically from the ku module\n",
    "    kernel_func = getattr(ku, settings['kernel'], None)\n",
    "    \n",
    "    # Prepare parameters, handling special cases for indices in rank_matrix\n",
    "    params = {}\n",
    "    for param_key, param_value in settings['params'].items():\n",
    "        if param_key == 'idx':\n",
    "            # Convert index names to actual positions\n",
    "            params[param_key] = rank_matrix.index.get_loc(param_value)\n",
    "        else:\n",
    "            params[param_key] = param_value\n",
    "\n",
    "    # Store the kernel function and its parameters\n",
    "    if kernel_func:\n",
    "        kernels[kernel_name] = (kernel_func, params)\n",
    "    else:\n",
    "        print(f\"Kernel function '{settings['kernel']}' not found in module 'ku'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallows_from_config = kernels[\"jaccard_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernels = {\n",
    "#    \"mallows_auto\": (ku.mallows_kernel, {\"nu\": \"auto\"}),\n",
    "#    \"jaccard_1\": (ku.jaccard_kernel, {\"k\": 1}),\n",
    "#    \"borda_OHE\": (ku.borda_kernel, {\"idx\": rank_matrix.index.get_loc(\"OHE\")}),\n",
    "#    \"borda_DE\": (ku.borda_kernel, {\"idx\": rank_matrix.index.get_loc(\"DE\")})\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mallows_from_dict = kernels[\"mallows_auto\"]\n",
    "#\n",
    "#print(mallows_from_config)\n",
    "#print(mallows_from_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will use the mallows kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNELNAME = \"jaccard_1\"\n",
    "KERNEL, KERNELARGS = kernels[KERNELNAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create some directories for the different experiments we run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create directories\n",
    "exp0_dir_name_parts = [f\"name={ALTERNATIVES}\"] + [f\"{key}={value}\" for key, value in EXPERIMENTAL_FACTORS.items() if value is not None]\n",
    "EXP0_DIR = FIGURES_DIR / \"_\".join(exp0_dir_name_parts)\n",
    "EXP1_DIR = EXP0_DIR / f\"{KERNELNAME}\"\n",
    "EXP2_DIR = EXP1_DIR / f\"nstar_N_ALPHA={ALPHA}_eps={EPS}_ci={LR_CONFIDENCE}_disjoint={DISJOINT}_replace={REPLACE}\"\n",
    "\n",
    "EXP2_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the experimental conditions pool to simulate running new experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_variable = next((key for key, value in EXPERIMENTAL_FACTORS.items() if value is None), None)\n",
    "ec_pool = df[ec_variable].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a few methods that will be run in a loop until our `ec_pool` is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by sampling from our `ec_pool` and converting our samples to the corresponding rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ecs(ec_pool, sample_size):\n",
    "    # Safety check such that we do not take more samples than we can take\n",
    "    sample_size = min(sample_size, len(ec_pool))\n",
    "\n",
    "    # Sample experimental conditions\n",
    "    return RNG.choice(ec_pool, sample_size, replace=False)\n",
    "\n",
    "def compute_rankings(ecs, rank_matrix):\n",
    "    rm_ = rank_matrix.loc[:, ecs]\n",
    "    na, nv = rm_.shape\n",
    "    \n",
    "    # Generate rankings from the data\n",
    "    rankings = ru.SampleAM.from_rank_function_dataframe(rm_)\n",
    "    \n",
    "    return rankings, nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get compute the variance, variance lower bound and MMDs of these rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_variance_and_lower_bound(rankings, n, kbar):\n",
    "    \n",
    "    variance = ku.var(rankings, use_rv=True, kernel=KERNEL, **KERNELARGS)\n",
    "    \n",
    "    var_lower_bound = gu.sample_mean_embedding_lowerbound(EPS, n, kbar=1, v=variance)\n",
    "    \n",
    "    return variance, var_lower_bound\n",
    "\n",
    "def calculate_mmds(rankings, nv):\n",
    "    mmds = {\n",
    "        n: mmd.subsample_mmd_distribution(\n",
    "            rankings, subsample_size=n, rep=100, use_rv=True, use_key=False,\n",
    "            seed=SEED, disjoint=DISJOINT, replace=REPLACE, kernel=KERNEL, **KERNELARGS\n",
    "        )\n",
    "        for n in range(2, nv // 2 + 1)\n",
    "    }\n",
    "    return mmds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create dataframes consisting of Generalizability scores and Quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generalizability_dataframe(mmds, logepss):\n",
    "    ys = {n: [mmd.generalizability(mmde, np.exp(logeps)) for logeps in logepss] for n, mmde in mmds.items()}\n",
    "    dfy = pd.DataFrame(ys, index=logepss).reset_index().melt(id_vars='index', var_name='n', value_name='generalizability')\n",
    "    dfy.rename(columns={'index': 'log(eps)'}, inplace=True)\n",
    "    dfy['n'] = dfy['n'].astype(int)\n",
    "    return dfy\n",
    "\n",
    "def create_quantiles_dataframe(mmds):\n",
    "    qs = {n: np.log(np.quantile(mmde, ALPHA)) for n, mmde in mmds.items()}\n",
    "    dfq = pd.DataFrame(list(qs.items()), columns=['n', 'log(eps)'])\n",
    "    dfq['log(n)'] = np.log(dfq['n'])\n",
    "    return qs, dfq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the quantiles dataframe to calculate `nstar`. To this end, we fit linear regression models on subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_regression_with_cv(dfq):\n",
    "    # Extracting features and target from DataFrame\n",
    "    X = dfq[['log(eps)']].values\n",
    "    y = dfq[['log(n)']].values\n",
    "\n",
    "    cv = KFold(n_splits=len(y))\n",
    "\n",
    "    residuals, linear_predictors = [], []\n",
    "\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        lr = LinearRegression().fit(X[train_index], y[train_index])\n",
    "\n",
    "        predicted = lr.predict(X[test_index])\n",
    "        residuals.extend(y[test_index] - predicted)\n",
    "\n",
    "        linear_predictors.append(lr)\n",
    "\n",
    "    return linear_predictors, residuals\n",
    "\n",
    "def predict_nstar(logepss, linear_predictors, dfq):\n",
    "    X = dfq[['log(eps)']].values\n",
    "    y = dfq[['log(n)']].values\n",
    "\n",
    "    ns_pred_cv = [np.exp(lr.predict(logepss.reshape(-1, 1)).reshape(-1)) for lr in linear_predictors]\n",
    "    \n",
    "    ns_pred = np.exp(LinearRegression().fit(X, y).predict(logepss.reshape(-1, 1)).reshape(-1))\n",
    "    \n",
    "    nstar_cv = [pred[np.argmax(logepss > np.log(EPS))] for pred in ns_pred_cv if not np.all(pred == 0)]\n",
    "    \n",
    "    nstar = ns_pred[np.argmax(logepss > np.log(EPS))]\n",
    "    \n",
    "    nstar_lower, nstar_upper = np.quantile(nstar_cv, [CI_LOWER, CI_UPPER])\n",
    "\n",
    "    return ns_pred, ns_pred_cv, nstar, nstar_lower, nstar_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we plot the our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generalizability_and_quantiles(dfy, dfq, logepss, ns_pred, ns_pred_cv, mmds, qs, nstar, nstar_upper, nstar_lower):\n",
    "    # Create figure and axes\n",
    "    fig, axes = plt.subplots(2, 1, sharex=\"all\", figsize=(10, 8))\n",
    "\n",
    "    # Generalizability plot\n",
    "    ax = axes[0]\n",
    "    sns.lineplot(data=dfy, x=\"log(eps)\", y=\"generalizability\", hue=\"n\", ax=ax, palette=palette)\n",
    "    ax.hlines(ALPHA, ls=\"--\", xmin=np.min(logepss), xmax=np.max(logepss), color=\"black\")\n",
    "    for n in mmds.keys():\n",
    "        ax.vlines(qs[n], ymin=0, ymax=ALPHA, ls=\":\")\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    # Quantiles plot\n",
    "    ax = axes[1]\n",
    "    ymax = max(ns_pred)\n",
    "    sns.lineplot(data=dfq, x=\"log(eps)\", y=\"n\", ax=ax, ls=\"\", marker=\"o\", hue=\"n\", legend=False)\n",
    "    for n in mmds.keys():\n",
    "        ax.vlines(qs[n], ymin=n, ymax=ymax, ls=\":\")\n",
    "    ax.vlines(np.log(EPS), ymin=0.1, ymax=ymax, color=\"black\", ls=\"--\")\n",
    "    sns.lineplot(x=logepss, y=ns_pred, color=\"green\", ls=\"-.\", ax=ax)\n",
    "    for it, ns_tmp in enumerate(ns_pred_cv):\n",
    "        if np.max(ns_tmp) > 1000:\n",
    "            continue\n",
    "        sns.lineplot(x=logepss, y=ns_tmp, color=\"green\", ls=\"-.\", alpha=0.5, ax=ax)\n",
    "\n",
    "    # N* Lines\n",
    "    ax.hlines(nstar, xmin=np.min(logepss), xmax=np.log(EPS), ls=\"-\", color=\"red\")\n",
    "    ax.hlines(nstar_upper, xmin=np.min(logepss), xmax=np.log(EPS), ls=\"-\", color=\"red\", alpha=0.3)\n",
    "    ax.hlines(nstar_lower, xmin=np.min(logepss), xmax=np.log(EPS), ls=\"-\", color=\"red\", alpha=0.3)\n",
    "    ax.set_yscale(\"log\")\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    # Finalize and save\n",
    "    fig.suptitle(f\"Generalizability for N = {len(ecs):02d}\\n\"\n",
    "                 f\"n*(alpha={ALPHA}, eps={EPS}) = {np.ceil(nstar)}\\n\"\n",
    "                 f\"{LR_CONFIDENCE} confidence interval: [{np.ceil(nstar_lower)}, {np.ceil(nstar_upper)}]\")\n",
    "    plt.tight_layout()\n",
    "    if FORMAT == \"pdf\" or FORMAT == \"all\":\n",
    "        plt.savefig(EXP2_DIR / f\"N={len(ecs):02d}.pdf\")\n",
    "    if FORMAT == \"png\" or FORMAT == \"all\":\n",
    "        plt.savefig(EXP2_DIR / f\"N={len(ecs):02d}.png\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]can't invoke \"event\" command: application has been destroyed\n",
      "    while executing\n",
      "\"event generate $w <<ThemeChanged>>\"\n",
      "    (procedure \"ttk::ThemeChanged\" line 6)\n",
      "    invoked from within\n",
      "\"ttk::ThemeChanged\"\n",
      "100%|██████████| 5/5 [00:23<00:00,  4.73s/it]\n"
     ]
    }
   ],
   "source": [
    "total_iterations = (len(ec_pool) + 9) // SAMPLE_SIZE\n",
    "ecs = np.array([])\n",
    "out = []\n",
    "plt.ioff()\n",
    "\n",
    "for i in tqdm(range(total_iterations)):\n",
    "    # -- Sample new rankings from ec pool\n",
    "    ecs = sample_ecs(ec_pool, (i+1)*SAMPLE_SIZE)\n",
    "    rankings, nv = compute_rankings(ecs, rank_matrix)\n",
    "\n",
    "    # -- Compute the lower bound\n",
    "    variance, var_lower_bound = compute_variance_and_lower_bound(rankings, n=len(ecs), kbar=1)\n",
    "\n",
    "    # -- Compute mmds\n",
    "    mmds = calculate_mmds(rankings, nv)\n",
    "\n",
    "    # -- Compute generalizability and quantiles\n",
    "\n",
    "    # Prepare log(eps) scale\n",
    "    logepss = np.linspace(np.log(EPS) - 0.1, np.log(max(np.quantile(mmde, ALPHA) for mmde in mmds.values())) + 0.1, 1000)\n",
    "\n",
    "    # Dataframe for generalizability\n",
    "    dfy = create_generalizability_dataframe(mmds, logepss)\n",
    "\n",
    "    # Dataframe for quantiles\n",
    "    qs, dfq = create_quantiles_dataframe(mmds)\n",
    "\n",
    "    # Linear Regression with Cross-Validation\n",
    "    linear_predictors, residuals = perform_linear_regression_with_cv(dfq)\n",
    "    \n",
    "    # Predictions\n",
    "    ns_pred, ns_pred_cv, nstar, nstar_lower, nstar_upper = predict_nstar(logepss, linear_predictors, dfq)\n",
    "\n",
    "    # -- Plotting\n",
    "    plot_generalizability_and_quantiles(dfy, dfq, logepss, ns_pred, ns_pred_cv, mmds, qs, nstar, nstar_upper, nstar_lower)\n",
    "\n",
    "    out.append({\n",
    "        \"kernel\": KERNELNAME,\n",
    "        \"alpha\": ALPHA,\n",
    "        \"eps\": EPS,\n",
    "        \"disjoint\": DISJOINT,\n",
    "        \"replace\": REPLACE,\n",
    "        \"N\": len(ecs),\n",
    "        \"nstar\": nstar,\n",
    "        \"nstar_lower\": nstar_lower,\n",
    "        \"nstar_upper\": nstar_upper,\n",
    "        \"variance\": variance,\n",
    "        \"var_lower_bound\": var_lower_bound,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we generate a gif to show the changes when changing `n`. Also, we store the outputs to a file for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "if FORMAT == \"gif\" or FORMAT == \"all\":\n",
    "    images = [iio.imread(image) for image in glob.glob(str(EXP2_DIR / \"*.png\"))]\n",
    "    iio.mimwrite(EXP2_DIR / f\"nstar.gif\", images, duration=750,\n",
    "                    loop=0)\n",
    "\n",
    "# -- Store nstar predictions\n",
    "out = pd.DataFrame(out)\n",
    "out.to_parquet(EXP2_DIR / \"nstar.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
